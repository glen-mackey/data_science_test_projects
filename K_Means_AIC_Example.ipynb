{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "672ce324",
   "metadata": {},
   "source": [
    "# KMeans Clustering Forward - Inverse Project\n",
    "\n",
    "\n",
    "## Introduction to project\n",
    "\n",
    "\n",
    "### Background\n",
    "\n",
    "KMeans Clustering is a commonly used unsupervised machine learning technique for understanding which data points may be related based on similarity between feature variable values.  Because supervised learning techniques make use of labeled data, the accuracy of the fit can be assessing by splitting the data into training and testing set, fitting the model with the training set, and measuring the accuracy of the predictions on the testing set.  However, assessing the quality of the fit for an unsupervised model with an un-labeled data set is not so straight forward.  Presumably, the KMeans algorithm should do a better job of properly identifying clusters when the inter-cluster distances significantly exceeds intra-cluster data point distances, but accuracy should degrade as the clusters are moved closer together and the data points begin to overlap.\n",
    "\n",
    "\n",
    "### Overview of Project\n",
    "\n",
    "The goal of this project is to assess the fit of the KMeans clustering algorithm in `Scikit-Learn` by forward modeling a data set of several clusters with noise, applying the KMeans clustering algorithm to divide the generated data set into clusters, and then visualizing the sets of clusters to compare the forward and inverse models.  \n",
    "\n",
    "Selection of the number of clusters to use (K in KMeans) is accomplished by fitting the data with a series of K values and selecting the 'best' fit using the Akaike Information Criterion (AIC).  A more common strategy for selecting the 'best' fit is to plot the residual sum of squares versus the number of clusters and select the point of maximum curvature, i.e., the 'elbow' in the curve.  In my experience trying to apply this approach to picking regularization hyper-parameters in regression/inversion modeling, it is easy to pick the elbow visually, but automating the algorithm to pick the point of maximum curvature regularly fails because of noise in the plot that the eye can smooth over; this noise can come from many sources, e.g., an incomplete fit due to hitting an `it_max` in the clustering algorithm.  Since the goal of the project is to implement fully automated picking I felt that AIC was a more robust solution.\n",
    "\n",
    "Assessment of the accuracy of the fit is done visually, although in the future it could be quantified using a Fisher's Exact test of a $\\chi^2$-test.  The output are a pair of plots of the forward modeled data points, color coded by the true label, alongside the inverse modeled data points, color coded by the label assigned by the clustering algorithm; labels for the forward and inverse data are reconciled to avoid any label mismatch due to the order of the inverted cluster centroids provided by the KMeans algorithm.\n",
    "\n",
    "The overall algorithm is made interactive so the user can select forward model input values, run the full algorithm, and see the updated output simply by adjusting the values with slider widgets and hitting the 'Run' button.\n",
    "\n",
    "\n",
    "### Structure of Project\n",
    "\n",
    "The project is structured in four section: the forward model, the inverse model, data visualization, and interactive implementation.  Each section contians a series of relevant functions, culminating in a single function that implements that section of the algorithm.  For example, the inverse modeling section has functions to fit the forward modeled data with an inverse model of K clusters, to repeat this fit procedure for different K values, to 'score' each fit, to select the ideal K value based on the returned scores, and to reconcile labels to facilitate plotting, all called by a 'master' function for that section that returns the relevant output.  The 'master' functions for each of the first three sections are called in the `main_function()`, which itself is called by the `interact_manual()` function, in the interactive section of the program.  Thus, changing variable values using the interactive widgets generates new forward and inverse model data, which are visualized using the data visualization section.\n",
    "\n",
    "\n",
    "\n",
    "Scroll to the bottom of this page use this algorithm, or slowly work your way down to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93423c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preamble\n",
    "#Some of these packeges are probably not part of the normal distribution,\n",
    "#but I chose not to force install them\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from ipywidgets import interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7dac380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#centers Matplotlib figures on the page\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4b7e7",
   "metadata": {},
   "source": [
    "## Forward Model Section\n",
    "\n",
    "This section implements the forward model by generating a series of cluster along the perimeter of a circle.  This secion takes the number of clusters and the radius of the circle to define (x,y) values for the forward model cluster centers.  Normaly distributed random noise is then added to the data to create a cluster of data points.  The total number of all the data points across all clusters is set by the user.  This section returns a dictionary that contains the true cluster centers, (x,y) values for the individual data points, and the true cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ca93d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for defining cluster centers, making the clusters, and computing true distance between cluser centers\n",
    "\n",
    "def define_cluster_center(n, r, start_radians=math.pi/2):\n",
    "    #defines the centroid for each cluster of points\n",
    "    #clusters are equally spaced along perimiter of circle with radius r around origin\n",
    "    #n=number of clusters\n",
    "    #r=radius\n",
    "    #start_radians=angle to put first cluster center point, math.pi/2 means it starts at North\n",
    "    #returns x_y list of paired values\n",
    "    \n",
    "    #computes the radial positions in radians\n",
    "    rad=np.arange(n)*2*math.pi/n + start_radians\n",
    "    \n",
    "    #converts polar corrdinates to cartesian\n",
    "    #saves in list of tuples [(x0,y0), (x1,y1), ... , (xn,yn)]\n",
    "    #https://stackoverflow.com/questions/53074230/how-to-combine-list-of-x-and-list-of-y-into-one-x-y-list\n",
    "    x_y_list = list(zip(r*np.cos(rad), r*np.sin(rad)))\n",
    "    \n",
    "    #return(rad)\n",
    "    return(x_y_list)\n",
    "#testing define_cluster_center function\n",
    "#rad=define_cluster_center(6,1,0)\n",
    "#x_y_list=define_cluster_center(6,1,math.pi/2)\n",
    "#print(x_y_list)\n",
    "\n",
    "def euclidean_dist(x1,y1,x2,y2):\n",
    "    #computes euclidean distance between two points\n",
    "    #x1,x2,y1,y2 are x,y coordinates for the two points\n",
    "    #simplified 2D solution, not general nD solution\n",
    "    return(np.sqrt((x2-x1)**2 + (y2-y1)**2))\n",
    "\n",
    "#computes true distance between adjacent cluser centers\n",
    "#[-1] to [0], [0] to [1], etc.\n",
    "#dist_list=[euclidean_dist(*x_y_list[i],*x_y_list[i+1]) for i in range(-1, len(x_y_list)-1)]\n",
    "#print(dist_list)\n",
    "#print(sum(dist_list)/6)\n",
    "\n",
    "def make_clusters(x_y_list=[(0,0)], nn=1000, std=1):\n",
    "    #makes the clusters of data points\n",
    "    #x_y_list=list of tuples of x,y for centers of clusters\n",
    "    #n=total number of data points\n",
    "    #std=1sd for cluster data points around cluster center\n",
    "    \n",
    "    #for reasons of reproducibility I have turned set a consistent seed for the random number generator\n",
    "    #need to deactivate to do MonteCarlo simulations\n",
    "    return(make_blobs(n_samples=nn, n_features=2, centers=x_y_list, cluster_std=std, random_state=0))\n",
    "#testing for the make clusters function \n",
    "#test_clusters=make_clusters(x_y_list, n=1000, std=1)\n",
    "#test_clusters[0]\n",
    "\n",
    "def generate_fwd_data(n=6, r=1, std=1, nn=1000, start_radians=math.pi/2):\n",
    "    #master function for this section\n",
    "    #generates cluster centers and clustered data around centers\n",
    "    #n=number of clusters\n",
    "    #r=radius\n",
    "    #std=1sd for cluster data points around cluster center\n",
    "    #nn=number of data points\n",
    "    #start_radians=angle to put first cluster center point, math.pi/2 means it starts at North\n",
    "    #returns list of the center points and the data points\n",
    "    \n",
    "    #generates the centroids\n",
    "    x_y_list=define_cluster_center(n=n,r=r,start_radians=math.pi/2)\n",
    "    \n",
    "    #creates cluster blubs around the specified centers\n",
    "    data_points=make_clusters(x_y_list,nn=nn, std=std)\n",
    "    \n",
    "    #packages x_y_list and data points as a dictionary to pass as a single object\n",
    "    fwd_dict={'x_y_list':x_y_list, 'data_points':data_points}\n",
    "    \n",
    "    #return x_y_list, data_points\n",
    "    return fwd_dict\n",
    "#testing for generate_clusters\n",
    "#fwd_dict=generate_fwd_data(n=6, r=10, std=1, nn=1000, start_radians=math.pi/2)\n",
    "#x_y_list=fwd_dict['x_y_list']\n",
    "#test_data_points=fwd_dict['data_points']\n",
    "#test_data_points[0]\n",
    "#x_y_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1f40b9",
   "metadata": {},
   "source": [
    "## Inverse Model Section\n",
    "\n",
    "This section implements the inverrse model by taking the data points generated in the forward model section and fitting the data points with K clusters.  The data fit with different values of K, each fit is 'scored' by AIC, and the 'best' fit is returned.  Even if the inverse centroids perfectly line up with the forward modeled cluster centers, they may not be sorted in the same order by the KMeans algorithm, thus the labels for each data point could be wrong even if they have been perfectly clustered.  Labels are reconciled by matching the inverse centroids to their nearest foward modeled cluster centers.  This section returns the ideal K value, the corresponding `KMeans()` object, and an array of the tested AIC values for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03de595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to compute the clusters, AIC score, and select 'best' result\n",
    "\n",
    "def compute_clusters(X, n=6):\n",
    "    #computes a cluster object with n clusters for data points X\n",
    "    #X is the feature data set\n",
    "    #n is the number of clusters to compute, I am not sure why but I think n must be >=2 (no single cluster)\n",
    "    #returns the cluster object\n",
    "    \n",
    "    #for reasons of reproducibility I have turned set a consistent seed for the random number generator\n",
    "    clust_obj=KMeans(n_clusters = n, init='k-means++', random_state=0)#, random_state=0\n",
    "    \n",
    "    #fits the data points in feature data set\n",
    "    clust_obj.fit(X)\n",
    "    \n",
    "    return(clust_obj)\n",
    "#tests the cluster function\n",
    "#test_clust=compute_clusters(test_data_points[0], n=6)\n",
    "#print(test_clust.labels_)\n",
    "#test_clust.inertia_\n",
    "#len(test_clust.cluster_centers_)\n",
    "#rint(test_clust.score(test_data_points[0]))\n",
    "\n",
    "def KMeans_AIC(clust_fit, data_points):\n",
    "    #computes an AIC score for the current cluster fit\n",
    "    #clust_fit is the current kmeans cluster\n",
    "    #https://stats.stackexchange.com/questions/271516/akaike-information-criterion-for-k-means\n",
    "    #returns AIC value\n",
    "    \n",
    "    #do not assume data set has been scaled\n",
    "    #compute the mean of the data and the standard deviation distance\n",
    "    #if data has been scaled then standard deviation should be 1\n",
    "    mean_data=np.mean(data_points,axis=0)\n",
    "    #print(mean_data)\n",
    "    \n",
    "    #computes euclidean distance from mean data points to all data points\n",
    "    dist_from_mean=euclidean_dist(*mean_data,data_points[:,0],data_points[:,1])\n",
    "    #print(dist_from_mean)\n",
    "    \n",
    "    #computes the standard deviation of the data points from the mean\n",
    "    std_dist=np.sqrt(np.sum(dist_from_mean**2)/len(dist_from_mean-1))\n",
    "    #print(std_dist)\n",
    "    \n",
    "    #solves AIC score equation, assuming data is not scaled so std=1\n",
    "    #AIC=1/std^2 * SSQ(distance between point and nearest cluster center) \n",
    "    #    + 2 * num clusters * dimenss in each data point\n",
    "    AIC_val = 1/std_dist**2 * clust_fit.inertia_ + 2 * len(clust_fit.cluster_centers_) * clust_fit.n_features_in_\n",
    "    #print(2 * len(clust_fit.cluster_centers_) * clust_fit.n_features_in_)\n",
    "    \n",
    "    return(AIC_val)\n",
    "#testing\n",
    "#AIC_test=KMeans_AIC(test_clust,test_data_points[0])\n",
    "#print(AIC_test)\n",
    "\n",
    "\n",
    "def cluster_and_score(data_points, min_clust=2, max_clust=10):\n",
    "    #computes KMeans cluster fits and AIC score for the given set of data points\n",
    "    #for a number of clusters from k=min_clust to k=max_clust\n",
    "    #I don't think Kmeans algorithm allows for single cluster so min_clust>=2\n",
    "    #data points=the set of data points\n",
    "    #min_clust, max_clust are the miminum and maximum number of clusters to try and fit the data with\n",
    "    \n",
    "    #enforces min_clust>=2\n",
    "    min_clust=min([min_clust,2])\n",
    "    \n",
    "    #fits the data with k clusters\n",
    "    #I have adaptive algorithms that use a spline fit to search for the 'best' fit and can\n",
    "    #expand the search range beyon what was initialy specified, but for this project I am just goint to\n",
    "    #brute force through the options\n",
    "    clust_fit_list=[compute_clusters(data_points, k) for k in range(min_clust, max_clust+1)]\n",
    "    \n",
    "    #computes AIC values for all of the clusters \n",
    "    AIC_arr=np.array([KMeans_AIC(clust_fit, data_points) for clust_fit in clust_fit_list])\n",
    "    \n",
    "    #finds the minimum AIC value and returns the number of clusters\n",
    "    k_ind=np.argmin(AIC_arr)\n",
    "    ideal_k=k_ind+min_clust\n",
    "    #print(ideal_k)\n",
    "    \n",
    "    #returns the ideal number of clusters\n",
    "    #the corresponding cluster object\n",
    "    #and the AIC score array\n",
    "    return(ideal_k, clust_fit_list[k_ind], AIC_arr)\n",
    "#testing, test_data_points[0] are the x-y for the data points test_data_points[1] are the labels\n",
    "#ideal_k, clust_obj, AIC_arr=cluster_and_score(test_data_points[0], min_clust=2, max_clust=4)\n",
    "#AIC_arr\n",
    "#clust_obj.cluster_centers_\n",
    "#print(clust_obj.labels_.shape)\n",
    "\n",
    "def reconcile_labels(x_y_list,clust_obj1):\n",
    "    #even if the inverse modeled clusters in clust_obj are very similar in location to the \n",
    "    #forward modeled clusters in x_y_list, there is no garantuees the labels will be consistent\n",
    "    #matches clust_obj.cluster_centers_ to the closest value in x_y_list, and relabels the clusters\n",
    "    #based on that.\n",
    "    \n",
    "    #gets the number of labels in the forward model\n",
    "    num_fwd_labels=len(x_y_list)\n",
    "    #gets the number of labels in the inverse model\n",
    "    num_inv_labels=len(clust_obj1.cluster_centers_)\n",
    "    \n",
    "    #intializes a new labels matrix\n",
    "    #will be put in clust_obj.labels_reconciled_=new_labels\n",
    "    new_labels=np.zeros_like(clust_obj1.labels_)\n",
    "    \n",
    "    def update_label_val(new_labels, current_labels, current_value_to_change, new_label):\n",
    "        #takes new_labels and updates the current_labels where the values is the current_value_to_change\n",
    "        #to the new label\n",
    "        #new_labels=np.where(clust_obj1.labels_==fwd_label_inv_label[fwd_label],\n",
    "        #                   fwd_label,new_labels)\n",
    "        new_labels=np.where(current_labels==current_value_to_change,\n",
    "                            new_label,new_labels)\n",
    "        return(new_labels)\n",
    "    \n",
    "    #reconiles the labels using different approaches based on on how many inverse and forward labels there are\n",
    "    #there may be a more elegent way to do this, but I broke it into the case where there are more inverse labels and \n",
    "    #we need to match the the forward labels to the closes inverse label and deal with any excess inverse labels\n",
    "    #and the case where there are fewer inverse labels and we need to match the inverse labels to the closest\n",
    "    #forward label\n",
    "    if num_inv_labels>=num_fwd_labels:\n",
    "        #when there are as many or more inverse labels as there are forward labels\n",
    "        \n",
    "        #computes pairwise distance between the forward cluster points in x_y_list \n",
    "        #and the inverse cluster_points in clust_obj.cluster_centers_\n",
    "        dist_mat_fwd_inv=pairwise_distances(X=x_y_list, Y=clust_obj1.cluster_centers_)\n",
    "        \n",
    "        #looks for the minimum distance in each row\n",
    "        #this is the inverse label value that most closely corresponds to this forward centroid\n",
    "        #[14 15  9  8 12 11] means forward label 0 most closely aligns with inverse label 14, \n",
    "        #forward label 1 most closely aligns with inverse label 15\n",
    "        #this assumes the there are more inverse labels than forward labels\n",
    "        #if there are fewer inverse labels than we need to figure out which forward label most closely corresponds\n",
    "        #to the inverse label in a seperate step\n",
    "        fwd_label_inv_label=dist_mat_fwd_inv.argmin(axis=1)\n",
    "        \n",
    "        #print(clust_obj.cluster_centers_)\n",
    "        #print(clust_obj.labels_)\n",
    "        #print(dist_mat_fwd_inverse)\n",
    "        #print(fwd_label_inv_label)\n",
    "        \n",
    "        #list of values to indicate which inverse centroids correspond to which forward centroids \n",
    "        #once they are aligned in the reconciliation process\n",
    "        #intializa empty list of correct length\n",
    "        #list says which reconciled forward label the inverse label corresponds to\n",
    "        centroid_reconcile_labels=[None] * num_inv_labels\n",
    "        \n",
    "        #goes through and updates the inverse labels to their closest forward label\n",
    "        for fwd_label in range(num_fwd_labels):\n",
    "            #new_labels=np.where(clust_obj1.labels_==fwd_label_inv_label[fwd_label],\n",
    "             #                   fwd_label,new_labels)\n",
    "            new_labels=update_label_val(new_labels, clust_obj1.labels_, fwd_label_inv_label[fwd_label], fwd_label)\n",
    "            \n",
    "            centroid_reconcile_labels[fwd_label_inv_label[fwd_label]]=fwd_label\n",
    "            \n",
    "        #print(new_labels)\n",
    "        #print(centroid_reconcile_labels)\n",
    "        \n",
    "        if num_inv_labels>num_fwd_labels:\n",
    "            \n",
    "            #initiates a variable to be a rolling counter for the new labels to replace \n",
    "            #set as the last of the forward labels\n",
    "            new_label_val=num_fwd_labels-1\n",
    "            \n",
    "            #these are the inverse labels that did not correspond most closely correspond to a forward label\n",
    "            #and now need to be shifted since we may have already used this label name in reconciling \n",
    "            #forward and inverse labels in the last step\n",
    "            labels_to_shift=[i for i in range(num_inv_labels) if i not in fwd_label_inv_label]\n",
    "            #print(labels_to_shift)\n",
    "            \n",
    "            #steps through each of the inv_labels in labels_to_shift\n",
    "            #shifts them to the next available label number and updates the values in new_labels\n",
    "            for inv_label in labels_to_shift:\n",
    "                \n",
    "                #increments the new label value variable to keep track of the next available lable number\n",
    "                new_label_val+=1\n",
    "                \n",
    "                #reorders the inverse labels that do not correspond to a forward label\n",
    "                new_labels=update_label_val(new_labels, clust_obj1.labels_, inv_label, new_label_val)\n",
    "                \n",
    "                centroid_reconcile_labels[inv_label]=new_label_val\n",
    "                #print(new_label_val)\n",
    "            #print(centroid_reconcile_labels)\n",
    "        \n",
    "    else:\n",
    "        #when there fewer inverse labels than forward labels\n",
    "        \n",
    "        #computes pairwise distance between the forward cluster points in x_y_list \n",
    "        #and the inverse cluster_points in clust_obj.cluster_centers_\n",
    "        dist_mat_inv_fwd=pairwise_distances(X=clust_obj1.cluster_centers_, Y=x_y_list)\n",
    "        \n",
    "        #if there are fewer inverse labels than we need to figure out which forward label most closely corresponds\n",
    "        #to the inverse labels\n",
    "        #[5 2 0 3] mean inverse label 0 correponds most closely with forward label 5, \n",
    "        #and inverse label 1 matches most closely with forward label 2\n",
    "        inv_label_fwd_label=dist_mat_inv_fwd.argmin(axis=1)\n",
    "        #print(inv_label_fwd_label)\n",
    "        #this is already in the correct format for centroid_reconcile_labels\n",
    "        centroid_reconcile_labels=inv_label_fwd_label\n",
    "        \n",
    "        #goes through and updates the inverse labels to their closest forward label\n",
    "        for inv_label in range(num_inv_labels):\n",
    "            #new_labels=np.where(clust_obj1.labels_==fwd_label_inv_label[fwd_label],\n",
    "             #                   fwd_label,new_labels)\n",
    "            new_labels=update_label_val(new_labels, clust_obj1.labels_, inv_label, inv_label_fwd_label[inv_label])\n",
    "    \n",
    "    #print(clust_obj.labels_)\n",
    "    #print(new_labels)\n",
    "    \n",
    "    #updates clust_obj with the reconciled labels while preserving the original labels\n",
    "    clust_obj1.labels_reconcile_=new_labels\n",
    "    clust_obj1.centroid_reconcile_labels_=centroid_reconcile_labels\n",
    "    \n",
    "    return(clust_obj1)\n",
    "#testing\n",
    "#clust_obj=reconcile_labels(fwd_dict['x_y_list'],clust_obj)\n",
    "\n",
    "def fit_clusters(fwd_dict, min_clust=2, max_clust=10):\n",
    "    #master function for this section\n",
    "    #implements the full KMeans cluster fit\n",
    "    #fwd_dict=the dictionary of forward modeled data\n",
    "    #fwd_dict['data_points'][0] are the xy data points to fit\n",
    "    #min_clust=minimum number of clusters to try, needs to be >=2\n",
    "    #max_clust=max number of clusters to try, increasing number increases processing time\n",
    "    \n",
    "    \n",
    "    #fits the data with a clustering algorithm\n",
    "    #tries a series of numbers of clusters and chooses the 'ideal' answer based on AIC score\n",
    "    #returns the ideal_k value based on AIC score\n",
    "    #returns the cluster_object that corresponds to ideal_k\n",
    "    ideal_k, clust_obj, AIC_arr=cluster_and_score(fwd_dict['data_points'][0], min_clust, max_clust)\n",
    "    \n",
    "    #updates clust_obj to reconcile the labels to plot in a unified color scheme\n",
    "    clust_obj=reconcile_labels(fwd_dict['x_y_list'],clust_obj)\n",
    "    \n",
    "    return ideal_k, clust_obj, AIC_arr\n",
    "#testing\n",
    "#ideal_k, clust_obj, AIC_arr=fit_clusters(fwd_dict, min_clust=2, max_clust=12)\n",
    "#print(clust_obj.centroid_reconcile_labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1f7c3b",
   "metadata": {},
   "source": [
    "## Visualization Section 1 - `Matplotlib`\n",
    "\n",
    "This section was my first cut at visualizing the ouput of the foward and inverse models using subplots from `Matplotlib`.  While the plots look nice, I realized it would be nice to be able to zoom and move around the plots, which can not be done interactively with `Matplotlib`.  I abandonded this approach in favor of using `Plotly` in a second visualization section, but I decided to preserve the code I had already written for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3bedb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig=plt.figure(figsize=(12, 4))\n",
    "\n",
    "#matplotlib ploting, I think the plotly look better and you can zoom in\n",
    "#I will keep this code here in case I want to refer to it in the future\n",
    "    \n",
    "def initialize_fig(figsize=(24, 20)):\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    \n",
    "    return(fig)\n",
    "#testing\n",
    "#fig=initialize_fig()\n",
    "\n",
    "def scatter_plot_inverse_clusters(clust_obj, fwd_dict, fig):\n",
    "    #plots invese problem clusters, color coded by cluster number\n",
    "    #I considered marking mis clustered data points but it feels too crowded\n",
    "    #uses clust_obj.labels_reconcile_ so that cluster colors are consistent across plots\n",
    "\n",
    "    #unpacks fwd_dict\n",
    "    fwd_cluster_centers=fwd_dict['x_y_list']\n",
    "    data_points=fwd_dict['data_points']\n",
    "    #data_points[0] is x,y, data_points[1] are forward labels\n",
    "    fwd_xy=data_points[0]\n",
    "    fwd_label=data_points[1]\n",
    "    #print(fwd_xy)\n",
    "    \n",
    "    #number of clusters to use in making the plot\n",
    "    #extracted from the number of clusters in the cluster object\n",
    "    k_use=len(set(clust_obj.labels_))\n",
    "    \n",
    "    #extracts the maximum number of clusters that will be plotted\n",
    "    #this tries to match color ranges between plots\n",
    "    k_color=max([len(set(clust_obj.labels_)),len(fwd_cluster_centers)])\n",
    "    \n",
    "    #gets a color map so each cluster is plotted in a different color\n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, k_color))\n",
    "    \n",
    "    #adds the axis to the figure\n",
    "    ax=fig.add_subplot(2,2,1)\n",
    "    \n",
    "    #steps through each cluster number and plots it using the assigned color\n",
    "    #for k, col in zip(range(k_use), colors[:k_use]):\n",
    "    for k in range(k_use):\n",
    "        \n",
    "        #boolean for whether data points are members of the current cluster\n",
    "        cluster_member_bool = (clust_obj.labels_ == k)\n",
    "        \n",
    "        #sets color based on clust_obj.labels_reconcile_ so colors match between plots\n",
    "        k_reconcile=clust_obj.labels_reconcile_[cluster_member_bool][0]\n",
    "        col=colors[k_reconcile]\n",
    "        #print([k,k_reconcile])\n",
    "        \n",
    "        #recovers corresponding cluster center, which need not be \n",
    "        cluster_center = clust_obj.cluster_centers_[k]\n",
    "        \n",
    "        #plots the cluster data points\n",
    "        ax.plot(fwd_xy[cluster_member_bool,0], fwd_xy[cluster_member_bool,1], linewidth=0, color='w', \n",
    "                markerfacecolor=col, marker='.', markersize=10)\n",
    "        \n",
    "        #plots the cluster centroids\n",
    "        ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,  markeredgecolor='k', markersize=15)\n",
    "        \n",
    "    #returns the updated figure for further plotting\n",
    "    return (fig)\n",
    "#fig=scatter_plot_inverse_clusters(clust_obj, fwd_dict, fig)\n",
    "#fig.show()\n",
    "\n",
    "def scatter_plot_forward_clusters(clust_obj, fwd_dict, fig):\n",
    "    #plots forward problem clusters, color coded by cluster number\n",
    "    #I considered marking mis clustered data points but it feels too crowded\n",
    "    #uses clust_obj.labels_reconcile_ so that cluster colors are consistent across plots\n",
    "\n",
    "    #unpacks fwd_dict\n",
    "    fwd_cluster_centers=fwd_dict['x_y_list']\n",
    "    data_points=fwd_dict['data_points']\n",
    "    #data_points[0] is x,y, data_points[1] are forward labels\n",
    "    fwd_xy=data_points[0]\n",
    "    fwd_label=data_points[1]\n",
    "    \n",
    "    \n",
    "    #number of clusters to use in making the plot\n",
    "    #extracted from the number of clusters in the cluster object\n",
    "    k_use=len(fwd_cluster_centers)\n",
    "    \n",
    "    #extracts the maximum number of clusters that will be plotted\n",
    "    #this tries to match color ranges between plots\n",
    "    k_color=max([len(set(clust_obj.labels_)),len(fwd_cluster_centers)])\n",
    "    \n",
    "    #gets a color map so each cluster is plotted in a different color\n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, k_color))\n",
    "    \n",
    "    #adds the axis to the figure\n",
    "    ax=fig.add_subplot(2,2,3)\n",
    "    \n",
    "    #steps through each cluster number and plots it using the assigned color\n",
    "    for k, col in zip(range(k_use), colors[:k_use]):\n",
    "    #for k in range(k_use):\n",
    "    \n",
    "        #boolean for whether data points are members of the current cluster\n",
    "        cluster_member_bool = (fwd_label == k)\n",
    "        \n",
    "        ##sets color based on clust_obj.labels_reconcile_ so colors match between plots\n",
    "        #k_reconcile=clust_obj.labels_[cluster_member_bool][0]\n",
    "        #col=colors[k_reconcile]\n",
    "        #print([k,k_reconcile])\n",
    "        \n",
    "        #recovers corresponding cluster center, which need not be \n",
    "        cluster_center = fwd_cluster_centers[k]\n",
    "        \n",
    "        #plots the cluster data points\n",
    "        ax.plot(fwd_xy[cluster_member_bool,0], fwd_xy[cluster_member_bool,1], linewidth=0, color='w', \n",
    "                markerfacecolor=col, marker='.', markersize=10)\n",
    "        \n",
    "        #plots the cluster centroids\n",
    "        ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,  markeredgecolor='k', markersize=15)\n",
    "        \n",
    "    #returns the updated figure for further plotting\n",
    "    return (fig)\n",
    "#fig=scatter_plot_forward_clusters(clust_obj, fwd_dict, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e5aa1",
   "metadata": {},
   "source": [
    "## Visualization Section 2 - `Plotly` and `Matplotlib`\n",
    "\n",
    "This section was my second cut at visualizing the output of the function using a mix of `Plotly` and `Matplotlib` generated plots.  This section takes the forward modeled data in `fwd_dict` and the inverse modeled fit in `clust_obj`, and generates a pair of `Plotly` plots to show data point labeling and cluster centers/centroids in the forward and inverse models, as well as a pair of `Matplotlib` plots to visualize the confusion matrix for the labels and the results of the AIC fit.  The `Plotly` plots are dynamic and linked, so zooming in or panning in one results in a comensurate change in the other.  The `Matplotlib` plots are not dynamic, within any run of the plotting function, but present data that is suitable for static display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cd8b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#builds plots in plotly\n",
    "\n",
    "\n",
    "def build_dfs(fwd_dict,clust_obj):\n",
    "    #plotly seems to work best with dataframes so I am migrating cluster forward and inverse data to dataframe\n",
    "    #fwd_dict is the forward data and \n",
    "    \n",
    "    #print(fwd_dict['data_points'][0][:,0])\n",
    "    fwd_data_df=pd.DataFrame({'x': fwd_dict['data_points'][0][:,0],\n",
    "                              'y': fwd_dict['data_points'][0][:,1],\n",
    "                              'Labels': fwd_dict['data_points'][1],\n",
    "                              'Reconciled Labels': fwd_dict['data_points'][1],\n",
    "                              'Data Type':'Forward'})\n",
    "    \n",
    "    #print(fwd_data_df.head())\n",
    "    #print([fwd_dict['x_y_list'][i][0] for i in range(len(fwd_dict['x_y_list']))])\n",
    "    fwd_center_df=pd.DataFrame({'x': [fwd_dict['x_y_list'][i][0] for i in range(len(fwd_dict['x_y_list']))],\n",
    "                                'y': [fwd_dict['x_y_list'][i][1] for i in range(len(fwd_dict['x_y_list']))],\n",
    "                                'Labels':list(range(len(fwd_dict['x_y_list']))),\n",
    "                                'Reconciled Labels':list(range(len(fwd_dict['x_y_list']))),\n",
    "                                'Data Type':'Forward'})\n",
    "    #print(fwd_center_df.head(6))\n",
    "    inv_data_df=pd.DataFrame({'x': fwd_dict['data_points'][0][:,0],\n",
    "                              'y': fwd_dict['data_points'][0][:,1],\n",
    "                              'Labels': clust_obj.labels_,\n",
    "                              'Reconciled Labels': clust_obj.labels_reconcile_,\n",
    "                              'Data Type':'Inverse',\n",
    "                              'True Labels':fwd_dict['data_points'][1]})\n",
    "    \n",
    "    #print(inv_data_df.head())\n",
    "    #print((clust_obj.centroid_reconcile_labels_))\n",
    "    #print(list(range(len(clust_obj.cluster_centers_))))\n",
    "    #print(clust_obj.cluster_centers_)\n",
    "    inv_center_df=pd.DataFrame({'x': [clust_obj.cluster_centers_[i][0] for i in range(len(clust_obj.cluster_centers_))],\n",
    "                                'y': [clust_obj.cluster_centers_[i][1] for i in range(len(clust_obj.cluster_centers_))],\n",
    "                                'Labels': list(range(len(clust_obj.cluster_centers_))),\n",
    "                                'Reconciled Labels': clust_obj.centroid_reconcile_labels_,\n",
    "                                'Data Type':'Inverse'})\n",
    "    \n",
    "    #print(inv_center_df.head())\n",
    "    return fwd_data_df, fwd_center_df, inv_data_df, inv_center_df\n",
    "#testing\n",
    "#fwd_data_df, fwd_center_df, inv_data_df, inv_center_df = build_dfs(fwd_dict,clust_obj)\n",
    "#build_dfs(fwd_dict,clust_obj)\n",
    "\n",
    "def plot_centroids(fwd_data_df, fwd_center_df, inv_data_df, inv_center_df):\n",
    "    #builds a plotly express plot to visualize the fwd and inverse models\n",
    "    #px is easy but not sure on how to overlay centroids ontop of data points and tweak colors\n",
    "    \n",
    "    #stacks the two df into a single df to simplify plotting in plotly\n",
    "    stacked_data_points=pd.concat([fwd_data_df, inv_data_df], axis=0)\n",
    "    #converts 'Reconciled Labels' to string to simplify legend building\n",
    "    stacked_data_points['Reconciled Labels']=stacked_data_points['Reconciled Labels'].astype('str')\n",
    "    \n",
    "    \n",
    "    #generates the plots with the base data points\n",
    "    fig=px.scatter(stacked_data_points, x='x', y='y', color='Reconciled Labels', facet_col='Data Type')\n",
    "    \n",
    "    return(fig)\n",
    "#testing\n",
    "#fig=plot_centroids(fwd_data_df, fwd_center_df, inv_data_df, inv_center_df)\n",
    "#fig.show()\n",
    "\n",
    "def plot_centroids2(fwd_data_df, fwd_center_df, inv_data_df, inv_center_df):\n",
    "    #builds a plotly 1x2 plot to visualize the fwd and inverse models\n",
    "    \n",
    "    #creates a 1x2 subplot with linked x and y axes and adds titles\n",
    "    fig=make_subplots(rows=1, cols=2,\n",
    "                     shared_xaxes='all', shared_yaxes='all',\n",
    "                     subplot_titles=('Forward Data','Inverse Data'))\n",
    "    #print(fwd_data_df['Reconciled Labels'].to_list())\n",
    "    \n",
    "    #fwd plot\n",
    "    #data points\n",
    "    fig.add_trace(go.Scatter(x=fwd_data_df['x'], y=fwd_data_df['y'], mode='markers',\n",
    "                             marker=dict(color=fwd_data_df['Reconciled Labels'].to_list(),coloraxis=\"coloraxis\",\n",
    "                                        size=3,\n",
    "                                        line=dict(width=1,\n",
    "                                                    color='white'))),\n",
    "                 row=1, col=1)\n",
    "    #centroids\n",
    "    fig.add_trace(go.Scatter(x=fwd_center_df['x'], y=fwd_center_df['y'], mode='markers',\n",
    "                             marker=dict(color=fwd_center_df['Reconciled Labels'].to_list(),coloraxis=\"coloraxis\",\n",
    "                                        size=12,\n",
    "                                        line=dict(width=2,\n",
    "                                                    color='black'))),\n",
    "                 row=1, col=1)\n",
    "    \n",
    "    #inverse plot\n",
    "    #data points\n",
    "    fig.add_trace(go.Scatter(x=inv_data_df['x'], y=inv_data_df['y'], mode='markers',\n",
    "                             marker=dict(color=inv_data_df['Reconciled Labels'].to_list(),coloraxis=\"coloraxis\",\n",
    "                                         size=3,\n",
    "                                         line=dict(width=1,\n",
    "                                                    color='white'))),\n",
    "                 row=1, col=2)\n",
    "    #centroids\n",
    "    fig.add_trace(go.Scatter(x=inv_center_df['x'], y=inv_center_df['y'], mode='markers',\n",
    "                             marker=dict(color=inv_center_df['Reconciled Labels'].to_list(),coloraxis=\"coloraxis\",\n",
    "                                         size=12,\n",
    "                                         line=dict(width=2,\n",
    "                                                    color='black'))),\n",
    "                 row=1, col=2)\n",
    "    \n",
    "    #updates color scale to rainbow and removes color bar\n",
    "    fig.update_layout(coloraxis=dict(colorscale='Rainbow'), showlegend=False)\n",
    "    fig.update_coloraxes(showscale=False)\n",
    "    #generates the plots with the base data points\n",
    "    #fig=px.scatter(stacked_data_points, x='x', y='y', color='Reconciled Labels', facet_col='Data Type')\n",
    "    \n",
    "    return(fig)\n",
    "#upper_fig=plot_centroids2(fwd_data_df, fwd_center_df, inv_data_df, inv_center_df)\n",
    "#upper_fig.show()\n",
    "\n",
    "def build_confusion_matrix(inv_data_df, col_names):\n",
    "    #builds confusion matrix from inv_data_df\n",
    "    #confusion_mat=pd.crosstab(inv_data_df['Reconciled Labels'], inv_data_df['True Labels'])\n",
    "    confusion_mat=pd.crosstab(inv_data_df[col_names[0]], inv_data_df[col_names[1]])\n",
    "    \n",
    "    #print(confusion_mat)\n",
    "    \n",
    "    return(confusion_mat)\n",
    "#confusion_mat=build_confusion_matrix(inv_data_df)\n",
    "\n",
    "def initialize_fig(figsize=(14, 5)):\n",
    "    #initialize the matplotlib figure\n",
    "    #second row of figures\n",
    "    #I am sure there is a more automated way to determine figsize so that it scales appropriately\n",
    "    #with the size monitor being used, but I have figured it out\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    #fig=plt.figure()\n",
    "    \n",
    "    return(fig)\n",
    "\n",
    "def generate_confusion_matrix_plot(fig, inv_data_df):\n",
    "    #generates and plots the confusion matrix using seaborn\n",
    "    \n",
    "    #generates confusion matrix\n",
    "    confusion_mat=build_confusion_matrix(inv_data_df, ['Reconciled Labels','True Labels'])\n",
    "    #pint(confusion_mat)\n",
    "    \n",
    "    #adds a subplot to figure for the confusion matrix\n",
    "    ax=fig.add_subplot(1,2,1)\n",
    "    \n",
    "    #plots the confusion matrix, labels come from the dataframe, fmt='.0f' specifies integer\n",
    "    ax=sns.heatmap(confusion_mat, annot=True, fmt='.0f', cmap='Blues')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    #plt.show()\n",
    "    return(fig)\n",
    "#generate_confusion_matrix_plot(inv_data_df)\n",
    "\n",
    "def generate_AIC_arr_plot(fig, AIC_arr, min_clust, max_clust, x_y_list, ideal_k):\n",
    "    #generates and plots the confusion matrix using seaborn\n",
    "    \n",
    "    #plots the AIC values \n",
    "    \n",
    "    #adds a subplot to figure for the confusion matrix\n",
    "    ax=fig.add_subplot(1,2,2)\n",
    "    \n",
    "    #plots the confustion matrix, labels come from the dataframe, fmt='.0f' specifies integer\n",
    "    ax.plot(range(min_clust,max_clust+1), AIC_arr,'b.-')\n",
    "    ax.set_title('AIC Values for Number of Clusters')\n",
    "    ax.set_xlabel('Number of Clusters')\n",
    "    ax.set_ylabel('AIC value')\n",
    "    \n",
    "    #adds a vertical line at the true number of clusters in the forward model\n",
    "    ax.axvline(x=len(x_y_list), color='k', linestyle='--', label='True Num Clusters')\n",
    "    \n",
    "    #adds a vertical line at the inverse model selected number of clusters\n",
    "    ax.axvline(x=ideal_k, color='r', linestyle=':', label='Selected Num Clusters')\n",
    "    \n",
    "    #adds a legend for line\n",
    "    ax.legend()\n",
    "    \n",
    "    #plt.show()\n",
    "    return(fig)\n",
    "#generate_AIC_arr_plot(AIC_arr, 2, 12, x_y_list,ideal_k)\n",
    "\n",
    "def build_lower_fig(inv_data_df,AIC_arr, min_clust, max_clust, fwd_dict, ideal_k):\n",
    "#builds the lower figures in the output\n",
    "    fig=initialize_fig()\n",
    "    \n",
    "    #makes the confusion matrix plot\n",
    "    fig=generate_confusion_matrix_plot(fig,inv_data_df)\n",
    "    \n",
    "    #makes the AIC plot\n",
    "    fig=generate_AIC_arr_plot(fig,AIC_arr, min_clust, max_clust, fwd_dict['x_y_list'],ideal_k)\n",
    "    \n",
    "    #fig.show()\n",
    "    \n",
    "    return(fig)\n",
    "#lower_fig=build_lower_fig(inv_data_df,AIC_arr, 2, 12, x_y_list, ideal_k)\n",
    "\n",
    "def builds_all_plots(fwd_dict,clust_obj,AIC_arr, min_clust, max_clust, ideal_k):\n",
    "    #master function for this section\n",
    "    #builds the upper plotly plots\n",
    "    #and the lower confusion matrix and parameter selection plots\n",
    "    \n",
    "    #builds data frames for plotting\n",
    "    fwd_data_df, fwd_center_df, inv_data_df, inv_center_df = build_dfs(fwd_dict,clust_obj)\n",
    "    \n",
    "    #builds the upper plotly data point figures\n",
    "    print('These figures are dynamic and linked')\n",
    "    upper_fig=plot_centroids2(fwd_data_df, fwd_center_df, inv_data_df, inv_center_df)\n",
    "    upper_fig.show()\n",
    "    \n",
    "    #builds the lower confusion matrix and parameter selection plots\n",
    "    print('These figures are static')\n",
    "    lower_fig=build_lower_fig(inv_data_df,AIC_arr, min_clust, max_clust, fwd_dict, ideal_k)\n",
    "    #lower_fig.show()\n",
    "    return\n",
    "#testing output   \n",
    "#builds_all_plots(fwd_dict,clust_obj, AIC_arr, 2, 12, x_y_list, ideal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46961ce1",
   "metadata": {},
   "source": [
    "## Interactive Control Section\n",
    "\n",
    "This section implements all of the previous sections in `main_function()`, and ties `main_function()` to an `interact_manual()` widget.  By adjusting the input variable values with the widgets, a new forward model is generated, fit with an inverse model, and the results are visualized.  The inverse modeling and visualization sections require too much procesing time to live update results as you drag each widget slider bar, so a manual `Run_Interact` button is used to reduce lag.  Once values for the variables are set, clicking `Run_Interact` will run the algorithm and generate the plots.\n",
    "\n",
    "User inputs are: \n",
    "- `num_clusters` = the number of clusters to forward model\n",
    "- `radius` = the radius of the circle on whose perimeter the cluster centers are placed\n",
    "- `data_stdev` = the standard deviation of the noise used to generate each cluster of data points\n",
    "- `num_data_points` = the total number of data points to generate for all of the clusters\n",
    "- `max_clusters` = maximum number of clusters to try in the inverse model, defualts to `2*num_clusters`\n",
    "\n",
    "See what happens as the ratio of `radius` to `data_stdev` decreases, or when `max_clusters` is less than `num_clusters`, or both!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7b84dc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3013d32413bd428ab5fc77972436783e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=6, description='num_clusters', max=10, min=2), FloatSlider(value=10.0, dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.main_function(num_clusters, radius, data_stdev, num_data_points, max_clusters)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merges all of the functions into a single master function which forward models, inverse models, and plots\n",
    "#main fuction engages with the interact widget\n",
    "def main_function(num_clusters,radius,data_stdev,num_data_points, max_clusters):\n",
    "    #takes user input and generates the clusters\n",
    "    #then inverse models the clusters using KMeans\n",
    "    #and visualizes the results\n",
    "    \n",
    "    #inputs \n",
    "    #num_clusters=number of clusters to forward model\n",
    "    #radius=radius of the circle to place clusters on perimeter of\n",
    "    #data_stdev=1std noise on cluster data points\n",
    "    #num_data_points=total number of data points to be divided by n clusters\n",
    "    #max_clusters=the maximum number of clusters to try and fit the data with\n",
    "    \n",
    "    #KMeans() crashes with less than 2 clusters\n",
    "    min_clust=2 \n",
    "        \n",
    "    #forward model data and generate fwd_dict containing relevant \n",
    "    #data points, labels, and centroids\n",
    "    fwd_dict=generate_fwd_data(n=num_clusters, r=radius, std=data_stdev, nn=num_data_points, start_radians=math.pi/2)\n",
    "    \n",
    "    #inverse model the data points\n",
    "    #fit KMeans clustering model trying different numbers of clusters and selecting based on AIC\n",
    "    \n",
    "    ideal_k, clust_obj, AIC_arr=fit_clusters(fwd_dict, min_clust=min_clust, max_clust=max_clusters)\n",
    "    \n",
    "    #generates plots\n",
    "    builds_all_plots(fwd_dict,clust_obj, AIC_arr, min_clust=min_clust, max_clust=max_clusters, ideal_k=ideal_k)\n",
    "    \n",
    "    return\n",
    "#testing\n",
    "#main_function(6,10,1,1000)\n",
    "\n",
    "#builds the widgets\n",
    "num_clusters_widget=widgets.IntSlider(min=2, max=10, step=1, value=6)\n",
    "radius_widget=widgets.FloatSlider(min=0.1, max=25, step=0.1, value=10)\n",
    "data_stdev_widget=widgets.FloatSlider(min=0.1, max=5, step=0.1, value=1)\n",
    "num_data_points_widget=widgets.IntSlider(min=100, max=10000, step=10, value=1000)\n",
    "max_clusters_widget=widgets.IntSlider(min=2, max=30, step=1, value=12)\n",
    "\n",
    "#ties update_max_clusters_range to num_clusters_widget\n",
    "#defaults the max_clusters_widget value to 5 * num_clusters\n",
    "#and sets the max as 2 * num_clusters\n",
    "def update_max_clusters_range(*args):\n",
    "    max_clusters_widget.value = 2 * num_clusters_widget.value\n",
    "    max_clusters_widget.max = 5 * num_clusters_widget.value\n",
    "num_clusters_widget.observe(update_max_clusters_range, 'value')\n",
    "\n",
    "#uses interact function to build sliders for all of the input variables\n",
    "#The program takes too long to allow just sliding the sliders\n",
    "#instead we set the settings and then click run instead of constantly fighting lag\n",
    "interact_manual(main_function,num_clusters=num_clusters_widget,\n",
    "                              radius=radius_widget,\n",
    "                              data_stdev=data_stdev_widget,\n",
    "                              num_data_points=num_data_points_widget,\n",
    "                              max_clusters=max_clusters_widget)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
